Configure the CSV Import within File Data Visualizer
The File Data Visualizer feature can be found in Kibana under the Machine Learning > Data Visualizer section. 

generate mock data from 
https://www.mockaroo.com/

Import using 01.


Querys  >6

GET employee_details/_count

GET employee_details/_alias

GET employee_details/_mapping

GET employee_details/_search?size=10


GET employee_details/_search
{
  "query":{
    "match_phrase": {
      "last_name": "Janosevic"
    }
  }
}


GET employee_details/_search
{
  "query":{
    "match_phrase_prefix": {
      "firt_name": "fi"
    }
  }
}

GET employee_details/_search
{
  "query": {
    "query_string": {
      "default_field": "closeddate",
      "query": "*",
      "default_operator": "OR"
    }
  }
}



GET employee_details/_search
{
  "query":{
    "term": {
      "gender": {
        "value": "Male"
      }
    }
  }
}


GET employee_details/_search
{
  "query":{
    "terms": {
      "gender": [
        "Male"
      ]
    }
  },
  "fields": [
    "id","email","ip_address"
  ]
}


--------------------------------------------------

GET employee_details/_search
{
  "aggs": {
    "gender_count": {
      "terms": {
        "field":"gender"
      }
    }
  }, 
  "query": {
    "bool": {
      "should": [
        {
          "range": {
            "openedDate": {
              "gte": "01/05/2023",
              "lte": "now"
            }
          }
        },
        {
          "range":{
            "closeddate": {
              "gte": "01/05/2023",
              "lte": "now"
            }
          }
        }
      ]
    }
  },
  "_source": ["id","ip_address","email","gender"]
}

GET employee_details/_search
{
  "query":{
    "range":{
      "openedDate": {
        "gte": "01/05/2023",
        "lte": "now"
      }
    }
  }
}


GET employee_details/_search
{
  "query":{
    "range":{
      "closeddate": {
        "gte": "01/05/2023",
        "lte": "now"
      }
    }
  }
}


GET employee_details/_search
{
  "query":{
    "term": {
      "gender": {
        "value": "Male"
      }
    }
  }
}


GET employee_details/_search
{
  "query":{
    "terms": {
      "gender": [
        "Male"
      ]
    }
  },
  "fields": [
    "id","email","ip_address"
  ]
}
-------------------------------------------------------------------------
part 11

## prefix query
GET employee_details/_search
{
  "query": {
    "prefix": {
      "last_name": {
        "value": "Jan"
      }
    }
  }
}

##wildcard Query
GET employee_details/_search
{
  "query":{
    "wildcard": {
      "last_name": {
        "value": "sev"
      }
    }
  }
}

##Component query 
#must,filter,should
GET employee_details/_search
{
  "query":{
    "bool":{
      "must": [
        {
         "prefix":{
           "last_name": {
             "value": "Jan"
           }
         }
        }
      ],
      "filter": [
        {
          "range": {
            "openedDate": {
              "gte": "01/10/2005",
              "lte": "now"
            }
          }
        }
      ],
      "should": [
        {
          "term":{
            "first_name": {
              "value": "Alfi"
            }
          }
        },
        {
          "term": {
            "gender": {
              "value": "Female"
            }
          }
        }
      ]
    }
  }
}

-----------------------------------------------------------
part 12

##Index creation part 1 (Analysis)
1. Converting text into token or terms 
    sentence: "A quick brown fox jumped over the lazy dog"
    tokens: [quick, brown,fox, jump, over, lazy, dog]

Analysis is performed by:
  1. analyzer
  2. tokenizer
  3. token filter
  4. character filter 
  
  Where we use analysis?
    - query
    - Mapping parameter
    - index setting

   Analyzer
    - Analysing text into token or keywords to be search/indexed.
    - builds tokenstream
    - Analyzer are provide to parse and analyse different languages.
    
    Reader -> tokenizer  -> token filter -> tokenfilter -> token


-----------------------------------------------------------

PUT employee-details-copy
{
  "settings":{
     "analysis":{
       "filter": {
         "auto_filter":{
           "type": "edge_ngram",
           "min_gram":2,
           "max_gram":32
         }
       },
       "analyzer":{
         "myanalyzer":{
           "type":"standard",
           "max_token_length":5,
           "stopwords":"_english_"
         },
         "autocomplete":{
           "type":"custom",
           "tokenizer": "standard",
           "filter":["lowercase","auto_filter"]
         }
       }
     }
  },
  "mappings": {
    
  }
}
------------------------------------------------------------